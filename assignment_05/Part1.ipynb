{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPd1oFf7c0/Wz7Mid3UJFze",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruthiang/Ruth_data690/blob/main/assignment_05/Part1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Analysis with Python\n",
        "## 2/28/2022\n",
        "## Ruth Iang"
      ],
      "metadata": {
        "id": "UGM1oRn9uSSG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is data analysis?\n",
        "- A process of inspecting, cleansing, transforming and modeling data with the goal of discovering useful information, informing conclusion and supporting decision-making\n",
        "\n",
        "- The first part of the process of Data Analysis is usually tedious, it starts by gathering the data, cleaning it and transforming it for further analysis.\n",
        "  - This is where Python and the PyData tools excel. We’re going to be  using Pandas to read, clean and transform our data.\n",
        "- Modeling data means adapting real life scenarios to information systems.    \n",
        "  - Using inferential statistics to see if any patterns or models arise. \n",
        "  - For this, we’re going to be using the statistical analysis features of Pandas and visualizations from Matplotlib and Seaborn.\n",
        "- We try to find patterns and drive conclusions from it. The word “information” is key. \n",
        "- In the final step, we create readable reports and dashboards, aid others with the info. we have and provide evidence of what we find. Many will use the analyis and they might need to see diff. sides of the same info\n"
      ],
      "metadata": {
        "id": "MVmwg4Yfuvpx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Analysis Tools\n",
        "- auto managed tools are closed products, and tools that you can buy and start using right out of the box. Examples: excel, tableau and looker (most popular)\n",
        " - closed source, expensive, limited, easy to learn\n",
        "\n",
        "- programming languages or open tools are not sold by any individual vendor, but theyre a combination of languages, open source libraries and products. Ex: Python, R, and Julia (most popular)\n",
        " - open source, free(or very cheap), extremely powerful, steep learning curve\n"
      ],
      "metadata": {
        "id": "-pnoWTd6wd0Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why Python for Data Analysis?\n",
        "- It’s simple, intuitive and readable. It includes thousands of libraries \n",
        "- Python is free and open source. That means that there are thousands of eyes, very smart people seeing the internals of the language and the libraries. \n",
        "- \"correct\" language\n",
        "- powerful libraries(not just for Data Analysis)\n",
        "- amazing community, docs and conferences\n",
        "\n",
        "- When do we choose R?\n",
        "  - when R studio is needed, when dealing with advanced statistical methods, and when extreme performance is needed\n"
      ],
      "metadata": {
        "id": "I4GOLR6zxyb0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Data Analysis Process\n",
        "- 1. Data Extraction\n",
        "- 2. Data Cleaning\n",
        "- 3. Data Wrangling\n",
        "- 4. Analysis\n",
        "- 5. Action"
      ],
      "metadata": {
        "id": "atJTuPcD0Zsn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Analysis vs. Data Science\n",
        "- Data scientists have more programming and math skills that they can apply in Maching Learning and ETL processes\n",
        "\n",
        "- Data analysts have better communications kills, creating better reports, with stronger storytelling abilities"
      ],
      "metadata": {
        "id": "YCXgVeJd05vf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Python & PyData Ecosystem\n",
        "- pandas: The cornerstone of our Data Analysis job with Python\n",
        "- matplotlib: The foundational library for visualizations. Other libraries we’ll use will be built on top of matplotlib.\n",
        "- numpy: The numeric library that serves as the foundation of all calculations in Python.\n",
        "- seaborn: A statistical visualization tool built on top of matplotlib.\n",
        "- statsmodels: A library with many advanced statistical functions.\n",
        "- scipy: Advanced scientific computing, including functions for optimization, linear algebra, image processing and much more.\n",
        "- scikit-learn: The most popular machine learning library for Python (not deep learning)"
      ],
      "metadata": {
        "id": "_kRjjEfF05xJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How Python Data Analysts Think\n",
        "- Excel and tableau - less useful when the amount of records grow\n",
        "- Python - allows us to work big data fast which allows us to move our Data Analysis processes to other computers, for example in the cloud, without much overhead.\n",
        "-  Data Analysts that know Python and SQL are better paid than the ones that don’t know how to use programming tools.\n"
      ],
      "metadata": {
        "id": "C_O0eVO81Hj_"
      }
    }
  ]
}